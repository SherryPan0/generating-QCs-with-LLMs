Data-driven Natural Language Processing (NLP) methods have noticeably advanced in the past few years. These advances can be tied to the drastic growth of the quality of collaborative knowledge bases (KB) available on the World Wide Web. Such KBs contain vast amounts of up-to-date structured human knowledge and common sense data that can be exploited by NLP methods to discover otherwise-unseen semantic dimensions in text, aiding in tasks related to natural language understanding, classification, and retrieval. Motivated by these observations, we describe our research agenda for exploiting online human knowledge in Requirements Engineering (RE). The underlying assumption is that requirements are a product of the human domain knowledge that is expressed mainly in natural language. In particular, our research is focused on methods that exploit the online encyclopedia Wikipedia as a textual corpus. Wikipedia provides access to a massive number of real-world concepts organized in hierarchical semantic structures. Such knowledge can be analyzed to provide automated support for several exhaustive RE activities including requirements elicitation, understanding, modeling, traceability, and reuse, across multiple application domains. This paper describes our preliminary findings in this domain, current state of research, and prospects of our future work.